Screen is in full screen mode for all of you.
Okay. So, um
using lightboard also,
Um, so online students are able to see the greenboard for whatever you call it.
uh, little
Half of the board. We can see, okay.
Is it better?
Yes. Okay.
Okay. So, um
So some formulations. So they are going to be on the screen on the, on the slide deck. But then I thought, uh, few things you can do and then board also,
uh, so
let's motivate about the speech synthesis. I'm sure Dr. Has already talked about speech synthesis, um, and introductory classes but we'll go a little bit in detail.
Um, here.
so, um, in in, um,
Speech synthesis. There are 2 major parts.
The first part inspired by like things you can get the idea from this particular video.
I'm speaking English but those are just a few examples of the different languages that I can speak in.
so,
now um, remember when our prime minister was actually used bhashani, um,
Uh in encoder and decoder to speak in like give uh uh live telecast in multiple languages in Tamil Telugu Canada and all other languages.
He does not know either of them.
Probably right when he can't speak. So fluently in 1 of them, but then in the live telecast, he was speaking probably he was
No, not probably, he was speaking in Hindi, but then the lifetime he cast was happening in multiple languages. So in almost me a real time live telecast was happening, and this is like an example, um, that 1 can speak, uh, in near real time in different languages. So, you may not need to know the language.
another example is suppose um I'm I'm traveling to Japan, I don't know Japanese
but if you have to communicate currently what happens when you go to Japan or China somewhere, then you use actually.
Your Google phone and then um, do that.
Uh, conversation with with, with the native people over there, right? Those those who may not know English there
So so you you speak in English and then you use a TTS model or speech and this is a model to convert into Japanese.
They speak in Japanese, they understand from there, they speak in Japanese. And then the TTS model gives this speech and this is model gives me back the English version.
right now, the field has advanced much, um,
मच मोर और यम!
हर इस द सेकंड यम पार्ट!
सो सो इन द प्रीवियस पार्ट द आइडिया वास था आई'एम स्पीकिंग इन इंग्लिश एंड आई'एम गेटिंग ट्रांसलेटेड इन हिंदी राइट ओर और फ्रेंच और स्पेनिश आईटी वास स्पीच टू स्पीक सिंथेसिस द अदर कोल्ड बे।
यू नो दैट व्होस इमेज इस दिस।
वास ए कम का केयर नोट केरल।
So exactly. So but the, the point here is that
He is no more.
And the Indian elections while this is an example of deep fake, but in in elections, his, um, video was circulated.
Okay, giving a particular message.
Okay, so so what would have happened? Let me run the video and then you can guess, okay.
Elon.
it's a very long, uh,
Video. But then you you get the idea right now. The person is no more.
We have persons a lot of video clips and audio signals. I can we can learn actually some how how actually someone would actually
Speak anything.
Now, what I can do is, if I have a, um, using Foundation models or using any of these modern, um, AI algorithms, I can type in text whatever I want.
Him to say.
I have a trained model and that, that trained model, takes this text. And then parse all this information converts into a voice signal.
A waveform. Okay. So this is text to speech.
so that's a second kind of
Uh, Speech synthesis part.
Okay, so words I view essentially we have very prevalent examples of the second part when we have providing the text and we are generating the audio form. Okay. While in both the examples, I have videos but then um, just for the time being don't look at videos. It's adios are also that like equally important and they are all lipstick and so on so forth, right? So,
now, if you have to generate such a software, such a tool,
How we will go about it.
Simpler is text to speech.
Slightly tougher is speech to speech and we'll talk about both, okay? So so if you start with text to speech,
um, the very first thing is
We need to have a mapping, some sort of mapping some sort of, understanding of the text word and the speech word.
So,
Um, unless you're able to see my the board, right? That I'm going to write something.
so, if this is my text,
Space. This is my feature space.
Okay.
And this is all audio a voice.
Right? What I need actually I need, can I convert from here to here? And from here, to here,
So I need to learn a mapping, broadly.
I need to learn a mapping.
between text even and
स्पीच!
इन सुच ए वे था!
P1 इक्वल टू एम टाइम्स एस।
राइट!
स ई नीड टू हैव ई नीड टू लर्न ए मैपिंग फंक्शन विच कैन कन्वर्ट माय टेक्स्ट एंबेडिंग्स इन माय स्पीच एंबेडिंग्स एंड फ्रॉम द स्पीच इन मिडल आई कैन दो ए डिकोडिंग एंड जनरेटर स्पीक आउट।
Fine. So so so if if you have, let's say a speech, um, any speech encoder like rishab has taught some of those reaching coders, right? So so once we have the embedding, I can convert that into
user decoder to decode it.
Right. So, so for clear.
Now, what are the challenges? The challenges
It's not that straightforward. See if, if if we talk about any 2 embeddings like text to text,
so, okay, let
Let's let's with respect to nlu topic.
So nlu is not my area, but at least from the very basic fundamental concept,
if I have,
For text in English. Okay? And I have a text here. Hindi.
Right.
I can learn very simple mapping.
it means some mapping between e2h,
so that if I provide,
A text in Hindi, I can generate a text in English by processing by mapping. So it's like a dictionary.
Okay? So we do that, right? From the English dictionary. We all have done in our Childhood Days.
This is my English word. What is the Hindi part of it?
Or vice versa.
So so, so if we can use, this mapping is nothing but the dictionary.
So in text, we have done it.
Many times.
now, if you have
To do this in audio.
Points like that. What what is what is the duration of the audio clip, right?
How someone is actually, uh, accent of a person how someone is speaking, right?
and um,
Even even many intricate details for instance, how someone is facing the sentences?
And then when we are speaking, right? We when we speak, we actually utter a lot of um uh right the, these kinds of words.

It also happens if your English is not very fluent or the language. The second language is not very fluent. If it is not a mother tongue, then you have some errors.
In the translation. Because at the back of your mind, you have also a dictionary, God, gifted dictionary given right in brain.
what, what you are doing, essentially, you are speaking in Hindi in your brain and then that dictionary is converting and that after the conversion, when you are speaking,
Right. Broadly
so, so, so
That may have some errors because your dictionary from that translation may not be absolutely correct.
So those errors may also come in.
While your Hindi is completely fine, but in English translation, may not be verified.
So, how to minimize so? So then essentially this whole thing comes under from
the words to utterances, We have to take care of all these variations and that's where the mapping comes into picture that how to
To ensure that this mapping of, uh, different. Um,
Accent, variations different style variations can also be understood and map. While the correctness also is equally important.
So this is another view. Um uh 1, 1 of The Views, which actually a paper has talked about where you have a text module, you give it to your embedding uh, layer. Like the NL layer, NL layer gives you uh, the the
Linguistic features the the embeddings essentially. And then from there you do some procedure modeling. You actually do the, um, um, the you go through the entire process of generating, the waveform and, uh, tetron is essentially, the the text to Mel, uh, the mfcc cofficient extraction. So, if you have a text, can we convert that into an MFC cofficient? The model has been trained essentially that that's a dictionary.
so, so, the particular style of creating
That dictionary in where we are, converting everything into a male frequency uh Spectrum, right? And then you have a vocoder like a waved at or a wave Globe. You can use any of your favorite uh, uh, vocoder, which essentially converts into. It's like a voice decoder. And that's a short form of uh, vocoder is essentially a short form of voice decoder. So you decode into a voice signal where you actually do the end to end synthesis of
Voice signal from in.
In where input is your text.
Okay, so this is the bird's eye view.
So this is the first part of uh or 1 of the parts of uh Speech synthesis.
Any questions so far?
Online guys.
Um,
if not, I'll move forward, okay?
And uh, I I hope I'm Audible and everything is going good.
Okay, so
So, so, 1 of the things that we are also working in in the similar domain, but we have just added a few steps of Corrections.
so, what we have, um, essentially done is
Speech to speech. What we have been trying to do is essentially speech to speech.
Um, I think Russia has taught you guys. Alright, so um, he has been working on this. So what we do is like, suppose I'm I'm um right now discussing and Google has actually a transcription option in the Google, uh, recording. And then
Accordingly. We can actually do a transcription. Also.
So whatever I'm saying Google will transcribe it. It will not do conversion, it will do only transcription that's a facility right available.
so if I'm speaking something an automat automatic speech recognition module can simply just
transcribe it.
now, when I'm I'm doing the transcription,
either because I have made mistake in uh, speaking, the particular sentence or
the transcription can have would have created an error.
error suppose I have said when the moon comes in between the Sun and the Earth, the solar eclipse happens, but
I may have actually made a mistake and I may, I may have said that when the moon come in between Sun and this, right? Or, or
The module.
Google translator may have missed me saying comes would have it may have just like heard as come and this is the transcription. Now here is an error in the transcription either we can actually manually correct it or
Create a module.
Of um language correction or the grammar correction.
Okay, so we we can connect the grammar and then the machine translation can click in our module of, uh, text to text to get coming. Okay, now from English, the machine translation can do
For to Hindi, okay.
So from English to Hindi, we have now done a translation.
है कि बीच में आता है तो सूर्य ग्रहण होता है।
नो दिस ट्रांसलेशन हिज मेड न एरर ओके नो वे नीड एन कलेक्शन, मॉड्यूल, आईटी कैन बी एन मैन्युअल कलेक्शन और आईटी कैन बी जनरली लिखे नोट मैन्युअल ऑल द टाइम बट देवर हस टू बी एन ऑटोमेटेड माड्यूल आफ करेक्टिंग द ग्रामर इन द सेकंड लैंग्वेज अलसो ओके सो द सेकंड लैंग्वेज आफ्टर द ग्रामर करेक्शन इसे।
अवेलेबल नाउ राइट आफ्टर द कलेक्शन एंड दिन वे कैन एड एन टेक्स्ट टू स्पीक मॉड्यूल सो सो इन दिस?
Approach, what we are doing?
Right. So
English voice.
To English text.
Then English text to Hindi text, then, Hindi text to in the voice, right?
This was in part 1. The first video that I show if I have to do this, this is typically the part that 1 can actually think of doing it.
Most naive approach, I would say, or, or the, or the, um, the the first thought.
We can do something like this, right?
What is the problem in this?
Latency, what else?
Errors. Right. So so any step like automatic speech recognition making an error.
Would need to be rectified the machine translation error needs to be rectified, right? And machine and then like,
There is a translation from again from text to speech. So there are many scope or many, um, blocks for, um,
chances of more errors, right? So that is means while, uh, we are, we are using this bhasha project for creating more data.
We are using this actually pipeline to create data.
Not to actually solve the problem of uh Speech to speech synthesis.
Okay.
so,
सो सो फर व्हाट वे हैव अंडरस्टूड वन इस स्पीच सिंथेसिस वन अनदर इस टेक्स्ट टू स्पेस सिंथेसिस।
और स्पीच टू स्पीक सिंथेसिस कैन बे डन वा टेक्स्ट टू स्पेस सिंथेसिस।
सो हेयर व्हाट यू हैव डन इस एक्जेक्टली था। स्पीच टू टेक्स्ट देन टेक्स्ट टू टेक्स्ट एंड थें। टेक्स्ट टू स्पीक राइट!
हॉवेवर अस यू ऑल सैड लोट ऑफ़ लेटेंसी एरर स्कोप ऑफ़ एरर लोट का स्कोप ऑफ़ एरर एंड एरर कैन टॉक?
गेट एंड हैव लार्जर एरर्स व्हाई कैन'टी वी डायरेक्टली दो स्पीच टू स्पीक स्टिल सिंथेसिस सो सो सो फर्स्ट एंड फोरमोस्ट लेटेंसी विल को ऑफ वे डॉन'टी नीड टू कन्वर्ट इन सम अदर डोमेन ओके नो।
व्हाट वे हैव डन ओवर हेरे इस टेक्स्ट।
आईएफ वे से था वे हैव!
बोथ स्पीशीज।
Fast. Basically, this is my voice in English. This is a voice in Hindi.
Okay. So, the problem statement still is going to be something similar, only means I'm just trying to help you to say that, okay? That the text to speech, the concept in text to speech is similar to or or the concept in speech to speech is similar to texting speech, in
We don't have to go through that whole cycle of conversion from 1 to 1. Okay. So what happens now
So now we have to do is both the domains are all your signals, okay?
From my, this domain.
I need to import.
Okay, I need to encode my
wife signal, which is in English.
To voice signal, which is in Hindi and battery cost of back. Both signals have to be there, right? So when I'm doing
Is.
What I'm trying to do V of E.
Is equal to.
N of e in E of H of b h, okay?
And I'm coming back. All right. What we are doing?
This is the forward conversion.
Right? So V of e, equal to M of e h.
To VH.
Fine.
Now, when I'm doing this, what what we are trying to do.
of H equal to M of
HT, right? So this can be a different.
Mapper, right? This can be a different mapping approach.
In your window.
Sorry.
Sorry.
so, when I'm coming from here,
हेयर व्हाट वे हैव इस वे नीड टू जनरेट स इक्वल टू।
एम का?
ह इन वी!
फ्रॉम वी गिवन इस वी वी आर जेनरेटिंग वह ओके गिवन वह वे अरे जेनरेटिंग वी राइट सो थिस विल बी वी का ए इक्वल टू एम का ह इन।
सॉरी पीएच इन!
फाइन!
Now, would you like to have 2 different encoders, or sorry, 2 different? Mappers
Egg dictionary sufficient, right? You don't need both the dictionaries. Now, what can we do here? Essentially is, can we force?
Force.
Can we force that the 2 dictionaries that we are trying to create, are the 2 mappers that we are trying to create? They both actually are

So if you have to write the equation. So this is equation. Number 1, this is equation. Number 2 with the constraint that both the mappers are or both.
The um, conversion approaches are exactly same. So then we are not using 2 digits.
Right, so this essentially reduces your latency.
This right? So so you and then this also reduces your overall computational uh load on the system memory. Requirement everything, right. It just reduces okay.
सो वे कैन ट्रांसलेट फ्रॉम वन लैंग्वेज टू अनदर लैंग्वेज विथ द हेल्प ऑफ़ ए सिंगल डिश।
राइट सो सो वे से एक्चुअली वे विल गो थ्रू थे एंटीरे एल्गोरिथमिक डिटेल्स अलसो लाइक हाउ थिंग्स हैपन।
सो सो वे स्टार्ट विद द फर्स्ट वन गो फ्रॉम ए वेरी सिंपल एल्गोरिथम एक्चुअली वन ऑफ़ द अर्ली एल्गोरिथम ऑन रिमूविंग थे नॉइस!
ओके सो वे विल बिल्ड फ्रॉम थेरे सो दैट वी कैन अंडरस्टैंड हाउ थिस?
स्पीच सिंथेसिस यूजिंग।
द डिक्शनरी एल्गोरिथम और इनकोडर इनकोडर डिकोडर मॉडल वर्क थें। वे से लिखे हो वे रिप्लेस द नॉइस वाला पार्ट वेयर द लैंग्वेज वाला पार्ट एंड आईटी वर्क्स राइट ओके सो लेट'एस अंडरस्टैंड थे प्रोबलम फर्स्ट!
थिस वास द बेस पेपर फॉर बिल्डिंग थे इनपुट और डिकोडर मॉडल फॉर स्पीशीज ओके।
सो वे हैव ए पार्टिकुलर नॉइस आर्ट।
सो आईएफ यू यू गो टू रेलवे स्टेशन।
रेलवे स्टेशन राइट बैकग्राउंड एंड यू आर कॉलिंग ऑन फोन आईटी'एस योर कॉलिंग योर योर फैमिली मेंबर्स राइट फ्रॉम थे। रेलवे स्टेशन रेलवे स्टेशन।
व्हाट इस हैपनिंग एट द अदर एंड।
योर फैमिली मेंबर्स आर लिसनिंग जो वाट!
बैकग्राउंड बहुत सारा आ रहा होगा। राइट अ लॉट का बैकग्राउंड इनफॉरमेशन इस मस्ट बे गोइंग ऑन व्हाई इस स्पीच इस आल्सो सो आईएफ!
आईएफ यू आईएफ यू ट्रीट योर स्पीच सिग्नल स थे फोरग्राउंड!
ऑल द अदर नॉइस।
बैकग्राउंड!
नॉइस एट द रेलवे स्टेशन एवरीथिंग इस बैकग्राउंड आईएफ ई आईएफ ई आस्क यू थे कैन यू कैन वे बिल्ड एन आर्किटेक्चर विच ड्रॉप्स थे एंटीरे बैकग्राउंड पार्ट एंड प्रिजर्व्स ऑन द फॉर ग्रे।
व्हाट काइंड ऑफ़ अप्रोच यू कैन इम्मीडिएटली थिंक ऑफ़?
थ्रीसहोल्डिंग ओके बट!
remember, you're speaking and suddenly we should say
Um, and that is going to be much louder than your voice.
Right. And if it's a should what happens.
Your voice will actually be below the threshold.
So some sort of noise cancellation needs to be done, right? So can you think of a a noise cancellation algorithm
Stft short-term, we did for your transform.
Right? So, so if, if you use our traditional, um,
Speech processing approach. We convert our uh audio signals to um um stfd form and from stf
भी कन्वर्ट इन एमएससी फॉर्म्स एंड थें। वे एसेंशियली सुप्प्रेस थे। सिगनल एंड ऑफ़ द डे वे अरे ट्राईंग तो लाइक दो ए थ्रीसहोल्डिंग इन सम अदर स्पेस सम अदर फीचर स्पेस राइट एंड एंड थें। वे जस्ट से ओके नो वॅटीवर इस द लेफ्ट ओवर राइट आफ्टर थे। थ्रीसहोल्डिंग वे कन्वर्ट लाइक यूजिंग ए डिकोडर वे कन्वर्ट आईटी बैक इन थे ऑडियो सिग्नल एंड थें। पास आईटी हॉपफुली अगेन था माय वर्क बट वे डॉन'टी नो ओके सो ओबवियसली व्हेन व्हेन वे व्हेन वे अरे इन थे डीप लर्निंग वर्ल्ड एवरीथिंग इस डीप लर्निंग।
एचटीएफटी और एमएफसीसीआर नो ओल्ड स्कूल राइट शो दिस दिस इस एक्चुअली व्हाट यू आर टॉकिंग अबाउट थिस थिस पार्टिकुलर ब्लॉक डायग्राम तथा इस ओवर हेरे एसेंशियली आईटी टॉक्स अबाउट दैट वी कैन उसे एसटीएफटीएमएफसीसी थें। फ्रॉम तेरे तो एक्चुअली वे सेंड इट टू ए ए वेरी क्लासिकल ओल्ड स्कूल काइंड ऑफ़ डिकोडर विच सेपरेट्स आउट थे। सिगनल एंड थे।
नॉइस!
व्हाट आई'एम इंटरेस्टेड इन इस इन एन इनकोडर डिकोडर अप्रोच!
राइट सो सो वे वे मय नॉट नीड टू कन्वर्ट एनी।
Anything into mfcc or stfd? I followed by.
Can we? So
For a um, how many of you remember Auto encoders?
No, has taught Auto encoders in the class, right?
Um, Can someone tell me the um, formulations for auto encoder very quickly?
Um, input X.
Okay.
I have, I
know.
Output.
Excel.
Right.
And this is all fully connected.
Right.
So this this part is my encoder. This part is my encoder.
What is the last function?
Anyone else?
MSC MSC between
so MS.
Of.
X minus.
This is the last function.
Right.
so if this is my h,
H H is what.
equal to,
Here, if if um, the weights are w.
Dash.
H is equal to W. *
X.
Right.
And then x dash is equal to.
W Dash into h.
value over here then x dash equal to
W Dash w.

X right.
if you put this value over here,
W Dash w x.
Right.
So given X we need. We are obtaining W Dash and w.
For the sake of Simplicity, what we will do is we will say that whatever W is over here.
Here, it's a transport.
Not a different weight, it's the same weight.
so here also so
in place of creating 2, dictionaries, or 2 weight sets,
Right.
से मैं इंपोर्ट किया है। उसके उल्टे वेट से डिकोड करना चाहिए। अगर आईएफ वे कैन से डेट ट्रांसपोर्ट ट्रांस्पोज वेट से।
तो दिन वे कैन फोर्स?
ट्रांस्पोज डब्लू!
सो दिन आई डोंट नीड टू लर्न टू सेट्स आई। कैन लर्न, ओनली वन सेट ऑफ रेट्स एंड उसे योर व ट्रांस्पोज और कान कान दान विद आईटी।
सो दिस इस एन क्लासिकल फॉर्मूलेशन आफ ऑटो इनकोडर्स इनकोडर डिकोडर एसेंशियली ओके सो।
बट थें थिस इस हो थे फॉर्मूलेशन वर्क!
व्हाय डिड ई एक्चुअली टेल यू दिस नॉइस हटाना है और ऑडियो सिग्नल हस बोथ इन नॉइस अस वेल अस।
इनपुट सिगनल राइट आई हैव टू रिमूव थे। नॉइस अब लेट'एस ट्राय टू अंडरस्टैंड आई इरेज़ दिस दिस इस फाइन।

Okay, so we can think of mfcc or whatever ml Spectrum or whatever we or the raw module itself.
But we need to give a 1 dimensional embedding a 1 dimensional signal as input to my encoder.
I have to place that into some embedding space and then convert it back such that I generate, the clean signal out.
Okay, so Auto encoder from Deep learning class. If you remember Auto,
एक्सक्यूज मी यम वन ऑफ़ द फॉर्मूलेशन ऑफ़ आर्ट इनकोडर्स आई'एम वन ऑफ़ द फेमस कांबिनेशन ऑफ़ आर्ट इनकोडर इस डोजिंग आर्टिकल।
आईटी कैन बे दोएस थे डाटा आईएफ थे डाटा इस नॉइसी कैन आई रिकंस्ट्रक्ट द नॉन नॉइसी डाटा ओके सो हमारा प्रोब्लम एक्जेक्टली सेम है और इनपुट इस नॉइसी सो कैन ई कंस्ट्रक्ट द नॉइज्ड आउटपुट कैन आई सिंथेसिस एंड रिमूव थे। नॉइस आउट नॉइस आउट एंड कीप थे।
क्लीन सिग्नल सो आईएफ वे हैव माई इनपुट लेट'एस से।
वॉइस व विच इस क्लीन राइट सो वे क्लीन।
प्लस ए नॉइस बैकग्राउंड नॉइस ओके सो व्हाट वी गेट इस वी का।
ठीक है।
वे नीड तो एश्योर था वे अरे रिमूविंग दिस एट द नॉइस हैपन एंड वे कंस्ट्रक्ट!
You see?
Back. Okay.
So start with me.
I have used Excel over here, so bear with me.
Let me convert this into X.
Right.
Now, my important. So if I have my, uh, input as XC
so my, so this is
Encoder right.
So how should I write the formula or, or the, um, equation for encoder?
Encoder.
This XC, right? Sorry. Right now I have Excel.
I need to reconstruct SC back but what I have is Excel
registration noise when you're
XM, I obtain h.
Means H equal to.
व टाइम्स।
एक्स!
ठीक है।
नो फ्रॉम ह!
ई जेनरेट!
व्हाट बैक!
एक जनरेट करेंगे।
क्या जनरेट करेंगे?
डेनोइस्ड एक राइट सो आई नीड टू जनरेट एक दास।
ठीक है अभी दिखाते हैं हम लोग तो ये ह है दिस इस माय डिकोडर ओके।
सो व्हाट शुड हैपन ओवर हियर अभी एक दास क्या है वे जस्ट होल्ड हैंग ऑन?
सो व्हाट शुड बी बाय आउटपुट आफ एक्स।
एक डैश शी इक्व डब्लू ट्रांस्पोज रिमेंबर अभी।
That.
In place of w. Dash. Now we can live with W transpose.
right, so w transpose into
Right.
Right. Right.
Transpose.
W of.
Excel.
Here it is.
X C.
मजा आया अभी तक नहीं आया।
लॉस फंक्शन क्या है?
एक्स प्लस फंक्शन क्या है?
एक्स माइनस एक्स सी।
है नहीं!
माइंस!
क दास राइट सो क्लीन सिग्नल, अगर होता हमारे पास।
और थे रिकंस्ट्रक्टेड क्लीन सिग्नल वे हैव टू मिनिमाइज द डिफरेंस बिटवीन टू ओके फाइन।
नो लेट'एस एक्चुअल एंड दिस इस?
लेट'एस एक्स माइनस!
व ट्रांस्पोज व इन।
एक्स!
ओके!
Even a noisy signal.
And its clean, counterpart. We are trying to learn the weights.
W and W essentially W and W transpose.
So that I can obtain.
The clean signal back.
This is at the time of training once the training is done.
What we need essentially is an accent.
Okay, it will encode and give my Edge.
From Edge. I'll generate XC Dash.
और दिस एक्स दास बिकॉज ट्रेनिंग इस ओवर थिस एक डैश इस एक्चुअली ए डी नॉइस ओके सो थिस इस व्हाट एक्चुअली।
थिस पार्टिकुलर क्लास फंक्शन थिस पार्टिकुलर स्लाइड एक्चुअली हाइलाइट्स नो स्लाइड मे तेरे इस वन मोर स्मॉल अड़ों व्हाट इस इट स्माल अड़ों।
कैन अन्योन एक्चुअली लुक एट द स्मॉल अड़ों एंड एंड टेल मी यहां पे क्या किया है?
हा!
And what you're saying?
So that we are learning better so we can go much deeper.
Not not to skip means, I'm talking about the loss function.
Focus on the loss function. There is 1, add all thing in the loss function.
Right.
Now we need to add 1 more term and what is that term?
And why actually, we need to add that.
Yeah.
So, how do we know?
so, so, what essentially, we are trying to achieve here is
This first term?
Otherwise, what will happen?



so,
how do we control that? How do we
Regularize it.
The amount of noise that was emitted.
Only that much noise.
Okay, so we need to use the second.
What is the second number is?
Can someone tell me online guys?
Can you can you interpret the second term over here?
Huh.
This is better for.
Online guys.
Yes, sir. Okay. Okay.
so, um,
Fine. Right. So, so the online, guys, what is the, what is the meaning of the significance? And what, what the second term in the last function is doing? As I said, it's a regularization term
like, you know,
नहीं कोई टाइप नहीं कर रहा अच्छा।
ओके!
ओके सो दिन दिन लेट मी लेट मी एक्चुअली टेल यू कैसे है? क्या नौ लुक एट दिस डायग्राम अगेन?
Imagine for for a moment.
for the time being, let's let's understand from their
Fine.
You have to have reconstruct.
What, what we should do, we should think of him and noisy signal around.
And Noise.
Suppressing, the actual voice.
And reconstructing the noise back.
Right. That announcement. We want to recast.
Fine. So, what would be my last function of the the loss function
We have the original noise.
Right.
whatever is my original voice minus of
The reconstructed noise.
Right.
The construction.
Okay.
so, what is actually tells me what this this part, same Auto encoder
if it starts actually doing the Reconstruction of noise,
Means first term in this.
